<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>steerability on Lil&#39;Log</title>
    <link>https://wuxb09.github.io/test-lilian/tags/steerability/</link>
    <description>Recent content in steerability on Lil&#39;Log</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Fri, 23 Jun 2023 00:00:00 +0000</lastBuildDate><atom:link href="https://wuxb09.github.io/test-lilian/tags/steerability/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>LLM Powered Autonomous Agents</title>
      <link>https://wuxb09.github.io/test-lilian/posts/2023-06-23-agent/</link>
      <pubDate>Fri, 23 Jun 2023 00:00:00 +0000</pubDate>
      
      <guid>https://wuxb09.github.io/test-lilian/posts/2023-06-23-agent/</guid>
      <description>Building agents with LLM (large language model) as its core controller is a cool concept. Several proof-of-concepts demos, such as AutoGPT, GPT-Engineer and BabyAGI, serve as inspiring examples. The potentiality of LLM extends beyond generating well-written copies, stories, essays and programs; it can be framed as a powerful general problem solver.
Agent System Overview In a LLM-powered autonomous agent system, LLM functions as the agent&amp;rsquo;s brain, complemented by several key components:</description>
    </item>
    
    <item>
      <title>Prompt Engineering</title>
      <link>https://wuxb09.github.io/test-lilian/posts/2023-03-15-prompt-engineering/</link>
      <pubDate>Wed, 15 Mar 2023 00:00:00 +0000</pubDate>
      
      <guid>https://wuxb09.github.io/test-lilian/posts/2023-03-15-prompt-engineering/</guid>
      <description>Prompt Engineering, also known as In-Context Prompting, refers to methods for how to communicate with LLM to steer its behavior for desired outcomes without updating the model weights. It is an empirical science and the effect of prompt engineering methods can vary a lot among models, thus requiring heavy experimentation and heuristics.
This post only focuses on prompt engineering for autoregressive language models, so nothing with Cloze tests, image generation or multimodality models.</description>
    </item>
    
    <item>
      <title>Reducing Toxicity in Language Models</title>
      <link>https://wuxb09.github.io/test-lilian/posts/2021-03-21-lm-toxicity/</link>
      <pubDate>Sun, 21 Mar 2021 00:00:00 +0000</pubDate>
      
      <guid>https://wuxb09.github.io/test-lilian/posts/2021-03-21-lm-toxicity/</guid>
      <description>Large pretrained language models are trained over a sizable collection of online data. They unavoidably acquire certain toxic behavior and biases from the Internet. Pretrained language models are very powerful and have shown great success in many NLP tasks. However, to safely deploy them for practical real-world applications demands a strong safety control over the model generation process.
Many challenges are associated with the effort to diminish various types of unsafe content:</description>
    </item>
    
    <item>
      <title>Controllable Neural Text Generation</title>
      <link>https://wuxb09.github.io/test-lilian/posts/2021-01-02-controllable-text-generation/</link>
      <pubDate>Sat, 02 Jan 2021 00:00:00 +0000</pubDate>
      
      <guid>https://wuxb09.github.io/test-lilian/posts/2021-01-02-controllable-text-generation/</guid>
      <description>[Updated on 2021-02-01: Updated to version 2.0 with several work added and many typos fixed.] [Updated on 2021-05-26: Add P-tuning and Prompt Tuning in the &amp;ldquo;prompt design&amp;rdquo; section.] [Updated on 2021-09-19: Add &amp;ldquo;unlikelihood training&amp;rdquo;.]
There is a gigantic amount of free text on the Web, several magnitude more than labelled benchmark datasets. The state-of-the-art language models (LM) are trained with unsupervised Web data in large scale. When generating samples from LM by iteratively sampling the next token, we do not have much control over attributes of the output text, such as the topic, the style, the sentiment, etc.</description>
    </item>
    
  </channel>
</rss>
