<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:content="http://purl.org/rss/1.0/modules/content/">
  <channel>
    <title>math-heavy on Lil&#39;Log</title>
    <link>https://wuxb09.github.io/test-lilian/tags/math-heavy/</link>
    <description>Recent content in math-heavy on Lil&#39;Log</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 11 Jul 2021 00:00:00 +0000</lastBuildDate><atom:link href="https://wuxb09.github.io/test-lilian/tags/math-heavy/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>What are Diffusion Models?</title>
      <link>https://wuxb09.github.io/test-lilian/posts/2021-07-11-diffusion-models/</link>
      <pubDate>Sun, 11 Jul 2021 00:00:00 +0000</pubDate>
      
      <guid>https://wuxb09.github.io/test-lilian/posts/2021-07-11-diffusion-models/</guid>
      <description>[Updated on 2021-09-19: Highly recommend this blog post on score-based generative modeling by Yang Song (author of several key papers in the references)]. [Updated on 2022-08-27: Added classifier-free guidance, GLIDE, unCLIP and Imagen. [Updated on 2022-08-31: Added latent diffusion model.
So far, I&amp;rsquo;ve written about three types of generative models, GAN, VAE, and Flow-based models. They have shown great success in generating high-quality samples, but each has some limitations of its own.</description>
    </item>
    
    <item>
      <title>Flow-based Deep Generative Models</title>
      <link>https://wuxb09.github.io/test-lilian/posts/2018-10-13-flow-models/</link>
      <pubDate>Sat, 13 Oct 2018 00:00:00 +0000</pubDate>
      
      <guid>https://wuxb09.github.io/test-lilian/posts/2018-10-13-flow-models/</guid>
      <description>So far, I&amp;rsquo;ve written about two types of generative models, GAN and VAE. Neither of them explicitly learns the probability density function of real data, $p(\mathbf{x})$ (where $\mathbf{x} \in \mathcal{D}$) &amp;mdash; because it is really hard! Taking the generative model with latent variables as an example, $p(\mathbf{x}) = \int p(\mathbf{x}\vert\mathbf{z})p(\mathbf{z})d\mathbf{z}$ can hardly be calculated as it is intractable to go through all possible values of the latent code $\mathbf{z}$.
Flow-based deep generative models conquer this hard problem with the help of normalizing flows, a powerful statistics tool for density estimation.</description>
    </item>
    
    <item>
      <title>Policy Gradient Algorithms</title>
      <link>https://wuxb09.github.io/test-lilian/posts/2018-04-08-policy-gradient/</link>
      <pubDate>Sun, 08 Apr 2018 00:00:00 +0000</pubDate>
      
      <guid>https://wuxb09.github.io/test-lilian/posts/2018-04-08-policy-gradient/</guid>
      <description>[Updated on 2018-06-30: add two new policy gradient methods, SAC and D4PG.]  [Updated on 2018-09-30: add a new policy gradient method, TD3.]  [Updated on 2019-02-09: add SAC with automatically adjusted temperature].  [Updated on 2019-06-26: Thanks to Chanseok, we have a version of this post in Korean].  [Updated on 2019-09-12: add a new policy gradient method SVPG.]  [Updated on 2019-12-22: add a new policy gradient method IMPALA.</description>
    </item>
    
    <item>
      <title>A (Long) Peek into Reinforcement Learning</title>
      <link>https://wuxb09.github.io/test-lilian/posts/2018-02-19-rl-overview/</link>
      <pubDate>Mon, 19 Feb 2018 00:00:00 +0000</pubDate>
      
      <guid>https://wuxb09.github.io/test-lilian/posts/2018-02-19-rl-overview/</guid>
      <description>[Updated on 2020-09-03: Updated the algorithm of SARSA and Q-learning so that the difference is more pronounced. [Updated on 2021-09-19: Thanks to 爱吃猫的鱼, we have this post in Chinese].
A couple of exciting news in Artificial Intelligence (AI) has just happened in recent years. AlphaGo defeated the best professional human player in the game of Go. Very soon the extended algorithm AlphaGo Zero beat AlphaGo by 100-0 without supervised learning on human knowledge.</description>
    </item>
    
    <item>
      <title>The Multi-Armed Bandit Problem and Its Solutions</title>
      <link>https://wuxb09.github.io/test-lilian/posts/2018-01-23-multi-armed-bandit/</link>
      <pubDate>Tue, 23 Jan 2018 00:00:00 +0000</pubDate>
      
      <guid>https://wuxb09.github.io/test-lilian/posts/2018-01-23-multi-armed-bandit/</guid>
      <description>The algorithms are implemented for Bernoulli bandit in lilianweng/multi-armed-bandit.
Exploitation vs Exploration The exploration vs exploitation dilemma exists in many aspects of our life. Say, your favorite restaurant is right around the corner. If you go there every day, you would be confident of what you will get, but miss the chances of discovering an even better option. If you try new places all the time, very likely you are gonna have to eat unpleasant food from time to time.</description>
    </item>
    
    <item>
      <title>From GAN to WGAN</title>
      <link>https://wuxb09.github.io/test-lilian/posts/2017-08-20-gan/</link>
      <pubDate>Sun, 20 Aug 2017 00:00:00 +0000</pubDate>
      
      <guid>https://wuxb09.github.io/test-lilian/posts/2017-08-20-gan/</guid>
      <description>[Updated on 2018-09-30: thanks to Yoonju, we have this post translated in Korean!]  [Updated on 2019-04-18: this post is also available on arXiv.]
Generative adversarial network (GAN) has shown great results in many generative tasks to replicate the real-world rich content such as images, human language, and music. It is inspired by game theory: two models, a generator and a critic, are competing with each other while making each other stronger at the same time.</description>
    </item>
    
  </channel>
</rss>
